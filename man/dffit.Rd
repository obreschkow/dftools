% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dffit.R
\name{dffit}
\alias{dffit}
\title{Fit a generative distribution function, such as a galaxy mass function}
\usage{
dffit(x, selection = NULL, x.err = NULL, r = NULL, gdf = "Schechter",
  p.initial = NULL, prior = NULL, obs.selection = NULL,
  obs.sel.cov = NULL, n.iterations = 100, correct.lss.bias = FALSE,
  lss.weight = NULL, lss.errors = TRUE, n.bootstrap = NULL,
  n.jackknife = NULL, xmin = 5, xmax = 13, dx = 0.01,
  keep.eddington.bias = FALSE, write.fit = FALSE,
  add.gaussian.errors = TRUE, make.posteriors = TRUE)
}
\arguments{
\item{x}{is an N-by-D matrix (or N-element vector if D=1) containing the observed quantities of N objects (e.g. galaxies).}

\item{selection}{Specifies the effective volume \code{V(xval)} in which an object of (D-dimensional) property *true* \code{xval} can be observed. This volume can be specified in five ways:\cr\cr

(1) If \code{selection} can be a single positive number. This number will be interpreted as a constant volume, \code{V(xval)=selection}, in which all objects are fully observable. \code{V(xval)=0} is assumed outside the "observed domain". This domain is defined as \code{min(x)<=xval<=max(x)} for a scalar observable (D=1), or as \code{min(x[,j])<=xval[j]<=max(x[,j])} for all j=1,...,D if D>1. This mode can be used for volume-complete surveys or for simulated galaxies in a box.\cr\cr

(2) \code{selection} can be an N-element vector. The elements will be interpreted as the volumes of each galaxy. \code{V(xval)} is interpolated (linearly in \code{1/V}) for other values \code{xval}. \code{V(xval)=0} is assumed outside the observed domain, except if D=1 (as in the case of fitting mass functions), where \code{V(xval)=0} is assumed only if \code{xval<min(x)}, whereas for \code{xval>max(x)}, \code{V(xval)} is set equal to the maximum effective volume, i.e. the maximum of \code{selection}. \cr\cr

(3) \code{selection} can be a function of D variables, which directly specifies the effective volume for any \code{xval}, i.e. \code{Veff(xval)=selection(xval)}.\cr\cr

(4) \code{selection} can be a list (\code{selection = list(veff.values, veff.userfct)}) of an \code{N}-element vector \code{veff.values} and a \code{D}-dimensional function \code{veff.userfct}. In this case, the effective volume is computed using a hybrid scheme of modes (2) and (3): \code{V(xval)} will be interpolated from the N values of \code{veff.values} inside the observed domain, but set equal to \code{veff.userfct} outside this domain.\cr\cr

(5) \code{selection} can be a list of two functions and one 2-element vector: \code{selection = list(f, dVdr, rmin, rmax)}, where \code{f = function(xval,r)} is the isotropic selection function and \code{dVdr = function(r)} is the derivative of the total survey volume as a function of comoving distance \code{r}. The scalars \code{rmin} and \code{rmax} (can be \code{0} and \code{Inf}) are the minimum and maximum comoving distance limits of the survey. Outside these limits \code{V(xval)=0} will be assumed.\cr\cr}

\item{x.err}{specifies the observational uncertainties of the N data points. These uncertainties can be specified in four ways:\cr\cr

(1) If \code{x.err = NULL}, the measurements \code{x} will be considered exact.\cr\cr

(2) If \code{x.err} is a \code{N-by-D} matrix, the scalars \code{x.err[i,j]} are interpreted as the standard deviations of Gaussian uncertainties on \code{x[i,j]}.\cr\cr

(3) If \code{x.err} is a \code{N-by-D-by-D} array, the \code{D-by-D} matrices \code{x.err[i,,]} are interpreted as the covariance matrices of the D observed values \code{x[i,]}.\cr\cr

(4) \code{x.err} can also be a function of a D-vector \code{x} and an integer \code{i}, such that \code{x.err(x,i)} is the prior probability distribution function of the data point \code{i} to have the true value \code{x}. This function must be vectorized in the first argument, such that calling \code{x.err(x,i)} with \code{x} being a N-by-D matrix returns an N-element vector.\cr\cr}

\item{r}{Optional N-element vector specifying the comoving distances of the N objects (e.g. galaxies). This vector is only needed if \code{correct.lss.bias = TRUE}.}

\item{gdf}{Either a string or a function specifying the DF to be fitted. A string is interpreted as the name of a predefined mass function (i.e. functions of one obervable, \code{D=1}). Available options are \code{'Schechter'} for Schechter function (3 parameters), \code{'PL'} for a power law (2 parameters), or \code{'MRP'} for an MRP function (4 parameters). Alternatively, \code{gdf = function(xval,p)} can be any function of the \code{P} observable(s) \code{xval} and a list of parameters \code{p}. IMPORTANT: The function \code{gdf(xval,p)} must be fully vectorized in \code{xval}, i.e. it must output a vector of \code{N} elements if \code{xval} is an \code{N-by-P} array (such as the input argument \code{x}). Note that if \code{gdf} is given as a function, the argument \code{p.initial} is mandatory.}

\item{p.initial}{is a P-vector specifying the initial model parameters for fitting the DF.}

\item{prior}{is an optional function specifying the priors on the P model parameters. This function must take a P-dimensional vector \code{p} as input argument and return a scalar proportional to the natural logarithm of the prior probability of the P-dimensional model parameter \code{p}. In other words, \code{prior(p)} is an additative term for the log-likelihood. Note that \code{prior(p)} must be smooth and finite for the full parameter space. If \code{prior=NULL} (default), uniform priors are assumed.}

\item{obs.selection}{is an optional selection function of a D-vector \code{x}, which specifies the fraction (between 0 and 1) of data with *observed* values \code{x}, whose true value passes the selection function \code{selection} can be observed. Normally this fraction is assumed to be 1 and all the selections are assumed to be specified relative to the true value in \code{selection}. However, if the data were selected, for example, with a sharp cut in the observed values, this can be specified in \code{obs.selection}. IMPORTANT: The function \code{obs.selection(x)} must be fully vectorized, i.e. it must output a vector of \code{N} elements if \code{x} is an \code{N-by-D} matrix (such as the input argument \code{x}).}

\item{obs.sel.cov}{is an optional \code{D-by-D} matrix, only used if \code{obs.selection} is set. It specifies the mean covariance matrix of the data to estimate how much data has been scattered outside the observing range. If \code{obs.selection} is set, but \code{obs.sel.cov} is not specified, the code estimates \code{obs.sel.cov} from the mean errors of the data (only works for 1D data).}

\item{n.iterations}{Maximum number of iterations in the repeated fit-and-debias algorithm to evaluate the maximum likelihood.}

\item{correct.lss.bias}{If \code{TRUE} the \code{distance} values are used to correct for the observational bias due to galaxy clustering (large-scale structure). The overall normalization of the effective folume is chosen such that the expected mass contained in the survey volume is the same as for the uncorrected effective volume.}

\item{lss.weight}{If \code{correct.lss.bias==TRUE}, this optional function of a \code{P}-vector is the weight-function used for the mass normalization of the effective volume. For instance, to preserve the number of galaxies, choose \code{lss.weight = function(x) 1}, or to perserve the total mass, choose \code{lss.weight = function(x) 10^x} (if the data \code{x} are log10-masses).}

\item{lss.errors}{is a logical flag specifying whether uncertainties computed via resampling should include errors due to the uncerainty of large-scale structure (LSS). If \code{TRUE} the parameter uncerainties are estimated by refitting the LSS correction at each resampling iteration. This argument is only considered if \code{correct.lss.bias=TRUE} and \code{n.bootstrap>0}.}

\item{n.bootstrap}{If \code{n.bootstrap} is an integer larger than one, the data is resampled \code{n.bootstrap} times using a non-parametric bootstrapping method to produce more accurate covariances. These covariances are given as matrix and as parameter quantiles in the output list. If \code{n.bootstrap = NULL}, no resampling is performed.}

\item{n.jackknife}{If \code{n.jackknife} is an integer larger than one, the data is jackknife-resampled \code{n.jackknife} times, removing exactly one data point from the observed set at each iteration. This resampling adds model parameters, maximum likelihood estimator (MLE) bias corrected parameter estimates (corrected to order 1/N). If \code{n.jackknife} is larger than the number of data points N, it is automatically reduced to N.  If \code{n.jackknife = NULL}, no such parameters are deterimed.}

\item{xmin, xmax, dx}{are \code{P}-element vectors (i.e. scalars for 1-dimensional DF) specifying the points (\code{seq(xmin[i],xmax[i],by=dx[i])}) used for some numerical integrations.}

\item{keep.eddington.bias}{If \code{TRUE}, the data is not corrected for Eddington bias. In this case no fit-and-debias iterations are performed and the argument \code{n.iterations} will be ignored.}

\item{write.fit}{If \code{TRUE}, the best-fitting parameters are displayed in the console.}

\item{add.gaussian.errors}{If \code{TRUE}, Gaussian estimates of the 16 and 84 percentiles of the fitted generative distribution function (gdf) are included in the sublist \code{grid} of the output.}

\item{make.posteriors}{If \code{TRUE}, posterior probability distributions of the observed data are evaluated from the best fitting model.}
}
\value{
The routine \code{dffit} returns a structured list, which can be interpreted by other routines, such as \code{\link{dfwrite}}, \code{\link{dfplot}}, \code{\link{dfplotcov}}, \code{\link{dfplotveff}}. The list contains the following sublists:

\item{data}{contains the input arguments \code{x}, \code{x.err}, \code{r} and \code{lss.weight}, as well as the integers \code{n.data} and \code{n.dim} specifying the number of objects (N) to be fitted and the dimension (D) of the observables. In other words, \code{n.data} and \code{n.dim} are the number of rows and columns of \code{x}, respectively.}

\item{selection}{is a list describing the selection function of the data used when fitting the generative DF. The most important entries in this list are:\cr\cr
\code{veff} is a function of a D-dimensional vector, specifying the effective volume associated with an object of properties xval. If LSS is corrected for, i.e. if the argument \code{correct.lss.bias} is set to \code{TRUE}, this function is the final effecive volume, including the effect of LSS.\cr\cr
\code{veff.no.lss} is a function of a D-dimensional vector, specifying the effecive volume associate with an object, if LSS were not accounted for. This function is indentical to \code{veff}, if LSS is not accounted for in the fit, i.e. if the argument \code{correct.lss.bias} is set to \code{FALSE}.\cr\cr
\code{mode} is an integer specifying the format of the input argument \code{selection}.}

\item{fit}{is a list describing the fitted generative distribution function. Its most important entries are:\cr\cr
\code{p.best} is a P-vector giving the most likely model parameters according to the MML method.\cr\cr
\code{p.sigma} and \code{p.covariance} are the standard deviations and covariance matrices of the best-fitting parameters in the Gaussian approximation from the Hessian matrix of the modified likelihood function.\cr\cr
 \code{gdf} is a function of a D-dimensional vector, which is the generative DF, evaluated at the parameters \code{p.best}.\cr\cr
 \code{scd} is a function of a D-dimensional vector, which gives the predicted source counts of the most likely model, i.e. scd(x)=gdf(x)*veff(x).}

\item{posteriors}{is a list specifying the posterior PDFs of the observed data, given the best-fitting model. It contains the following entries:\cr\cr
\code{x.mean} is an N-by-D dimensional array giving the D-dimensional means of the posterior PDFs of the N objects.\cr\cr
\code{x.mode} is an N-by-D dimensional array giving the D-dimensional modes of the posterior PDFs of the N objects.\cr\cr
\code{x.stdev} is an N-by-D dimensional array giving the D-dimensional standard deviations of the posterior PDFs of the N objects.\cr\cr
\code{x.random} is an N-by-D dimensional array giving one random D-dimensional value drawn from the posterior PDFs of each of the N objects.}

\item{model}{is a list describing the generative DF used to model the data. The main entries of this list are:\cr\cr
\code{gdf(xval,p)} is the generative DF to be fitted, written as phi(x|theta) in the reference publication.\cr\cr
\code{gdf.equation} is a text-string representing the analytical equation of \code{gdf}.\cr\cr
\code{parameter.names} is a P-vector of expressions (see \code{\link{expression}}), specifying the names of the parameters.\cr\cr
\code{n.para} is an integer specifying the number P of model parameters.}

\item{grid}{is a list of arrays with numerical evaluations of different functions on a grid in the D-dimensional observable space. This grid is used for numerical integrations and graphical representations. The most important list entries are:\cr\cr
\code{x} is a M-by-D array of M points, defining a regular cartesian grid in the D-dimensional observable space.\cr\cr
\code{xmin} and \code{xmax} are D-vectors specifying the lower and upper boundary of the grid in the D-dimensional observable space.\cr\cr
\code{dx} is a D-vector specifying the steps between grid points.\cr\cr
\code{dvolume} is a number specifying the D-dimensional volume associated with each grid point.\cr\cr
\code{n.points} is the number M of grid points.\cr\cr
\code{gdf} is an M-vector of values of the best-fitting generative DF at each grid point. The additional entries \code{gdf.error.neg} and \code{gdf.error.pos} define the 68\%-confidence range in the Hessian approximation of the parameter covariances. The optional entries \code{gdf.quantile.#} are different quantiles, generated if the input argument \code{n.bootstrap} is set.\cr\cr
\code{veff} is an M-vector of effective volumes at each grid point.\cr\cr
\code{scd} is an M-vector of predicted source counts according to the best-fitting model.\cr\cr
\code{scd.posterior} is an M-vector of observed source counts derived from the posterior PDFs of each object.\cr\cr
\code{effective.counts} is an M-vector of fractional source counts derived from the posterior PDFs of each object.}

\item{options}{is a list of various optional input arguments of \code{dffit}.}
}
\description{
This function finds the most likely P-dimensional model parameters of a D-dimensional distribution function (DF) generating an observed set of N objects with D-dimensional observables x, accounting for measurement uncertainties and a user-defined selection function. For instance, if the objects are galaxies, \code{dffit} can fit a mass function (D=1), a mass-size distribution (D=2) or the mass-spin-morphology distribution (D=3). A full description of the algorithm can be found in Obreschkow et al. (2017).
}
\details{
For a detailed description of the method, please refer to the peer-reviewed publication by Obreschkow et al. 2017 (in prep.).
}
\examples{
# For a quick overview of some key functionalities run
dfexample()
# with varying integer arguments 1, 2, 3, 4.

# The following examples introduce the basics of dftools step-by step.
# First, generate a mock sample of 1000 galaxies with 0.5dex mass errors, drawn from
# a Schechter function with the default parameters (-2,11,-1.3):
dat = dfmockdata(n=1000, sigma=0.5)

# show the observed and true log-masses (x and x.true) as a function of true distance r
plot(dat$r,dat$x,col='grey'); points(dat$r,dat$x.true,pch=20)

# fit a Schechter function to the mock sample without accounting for errors
survey1 = dffit(dat$x, dat$veff)

# plot fit and add a black dashed line showing the input MF
ptrue = dfmodel(output='initial')
mfplot(survey1, xlim=c(1e6,2e12), ylim=c(2e-4,2),
show.data.histogram = TRUE, p = ptrue, col.fit = 'purple')

# now, do the same again, while accountting for measurement errors in the fit
# this time, the posterior data, corrected for Eddington bias, is shown as black points
survey2 = dffit(dat$x, dat$veff, dat$x.err)
mfplot(survey2, show.data.histogram = NA, add = TRUE)

# show fitted parameter PDFs and covariances with true input parameters as black points
dfplotcov(list(survey2,survey1,ptrue),pch=c(20,20,3),col=c('blue','purple','black'),nstd=15)

# show effective volume function
dfplotveff(survey2)

# now create a smaller survey of only 30 galaxies with 0.5dex mass errors
dat = dfmockdata(n=30, sigma=0.5)

# fit a Schechter function and determine uncertainties by resampling the data
survey = dffit(dat$x, dat$veff, dat$x.err, n.bootstrap = 30)

# show best fit with 68\% Gaussian uncertainties from Hessian and posterior data as black points
mfplot(survey, show.data.histogram = TRUE, uncertainty.type = 1)

# show best fit with 68\% and 95\% resampling uncertainties and posterior data as black points
mfplot(survey, show.data.histogram = TRUE, uncertainty.type = 3)

# add input model as dashed lines
lines(10^survey$grid$x, survey$model$gdf(survey$grid$x,ptrue), lty=2)

}
\author{
Danail Obreschkow
}
\keyword{fit}
\keyword{function}
\keyword{mass}
\keyword{schechter}
